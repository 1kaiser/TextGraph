ðŸ“š GAT ATTENTION MECHANISM - ASCII VISUALIZATION GUIDE
====================================================

ðŸŽ¯ SCENARIO: Paragraph with Target Sentence Analysis

PARAGRAPH: "Neural networks are powerful tools. Graph attention mechanisms capture relationships. 
           These models transform natural language processing."

TARGET SENTENCE: "Graph attention mechanisms capture relationships"
SENTENCE TOKENS: ["Graph", "attention", "mechanisms", "capture", "relationships"]

STEP 1: PARAGRAPH TOKENIZATION
=============================
FULL_TOKENS = ["Neural", "networks", "are", "powerful", "tools", "Graph", 
               "attention", "mechanisms", "capture", "relationships", "These", 
               "models", "transform", "natural", "language", "processing"]

INDICES:        0        1        2       3         4       5
               6         7          8        9            10      
               11       12        13       14        15

TARGET_SENTENCE_INDICES = [5, 6, 7, 8, 9]  â† Focus tokens

STEP 2: GAT ATTENTION COMPUTATION
=================================
For target sentence "Graph attention mechanisms capture relationships":

ATTENTION SCORES (e_ij) - Raw values before softmax:
```
    PARAGRAPH CONTEXT (0-15)         TARGET SENTENCE (5-9)
    0   1   2   3   4   |  5   6   7   8   9  | 10  11  12  13  14  15
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
5 â”‚ 0.1 0.2 0.0 0.1 0.3 â”‚ 0.0 2.8 1.5 1.2 0.9â”‚ 0.2 0.4 0.1 0.2 0.1 0.0  â”‚ Graph
6 â”‚ 0.2 0.1 0.1 0.2 0.2 â”‚ 2.1 0.0 2.9 1.8 1.4â”‚ 0.1 0.3 0.2 0.1 0.3 0.2  â”‚ attention  
7 â”‚ 0.1 0.3 0.0 0.1 0.1 â”‚ 1.3 2.5 0.0 2.2 1.6â”‚ 0.2 0.1 0.1 0.2 0.1 0.1  â”‚ mechanisms
8 â”‚ 0.0 0.2 0.1 0.1 0.2 â”‚ 1.0 1.7 2.0 0.0 2.4â”‚ 0.1 0.2 0.3 0.1 0.2 0.1  â”‚ capture
9 â”‚ 0.1 0.1 0.0 0.2 0.1 â”‚ 0.8 1.2 1.4 2.1 0.0â”‚ 0.3 0.1 0.2 0.4 0.1 0.2  â”‚ relationships
```

HIGH ATTENTION PAIRS (> 2.0):
â€¢ Graph â†’ attention (2.8)      â€¢ attention â†’ mechanisms (2.9)
â€¢ attention â†’ Graph (2.1)      â€¢ mechanisms â†’ capture (2.2)  
â€¢ capture â†’ relationships (2.4) â€¢ relationships â†’ capture (2.1)

STEP 3: SOFTMAX NORMALIZATION
=============================
Normalized attention weights (Î±_ij) for TARGET SENTENCE:

```
ATTENTION MATRIX (After Softmax) - TARGET SENTENCE FOCUS:
        0    1    2    3    4    |   5    6    7    8    9   | 10   11   12   13   14   15
        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    5 â”‚ 0.02 0.03 0.01 0.02 0.04 â”‚ 0.00 0.52 0.18 0.15 0.08 â”‚ 0.03 0.05 0.02 0.03 0.02 0.01 â”‚ Graph
    6 â”‚ 0.03 0.02 0.02 0.03 0.03 â”‚ 0.19 0.00 0.58 0.24 0.17 â”‚ 0.02 0.04 0.03 0.02 0.04 0.03 â”‚ attention
    7 â”‚ 0.02 0.04 0.01 0.02 0.02 â”‚ 0.16 0.34 0.00 0.32 0.22 â”‚ 0.03 0.02 0.02 0.03 0.02 0.02 â”‚ mechanisms  
    8 â”‚ 0.01 0.03 0.02 0.02 0.03 â”‚ 0.12 0.21 0.28 0.00 0.41 â”‚ 0.02 0.03 0.04 0.02 0.03 0.02 â”‚ capture
    9 â”‚ 0.02 0.02 0.01 0.03 0.02 â”‚ 0.09 0.15 0.18 0.26 0.00 â”‚ 0.04 0.02 0.03 0.05 0.02 0.03 â”‚ relationships
```

STEP 4: COLOR MAPPING FOR VISUALIZATION
======================================

ATTENTION STRENGTH â†’ COLOR MAPPING:
â€¢ Î± â‰¥ 0.50: ðŸ”´ RED    (Very High Attention)
â€¢ Î± â‰¥ 0.30: ðŸŸ  ORANGE (High Attention)  
â€¢ Î± â‰¥ 0.15: ðŸŸ¡ YELLOW (Medium Attention)
â€¢ Î± â‰¥ 0.05: ðŸŸ¢ GREEN  (Low Attention)
â€¢ Î± <  0.05: âšª WHITE  (Minimal Attention)

COLORED ADJACENCY MATRIX (TARGET SENTENCE ONLY):
```
        Graph  attention  mechanisms  capture  relationships
        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Graph â”‚  âšª      ðŸ”´         ðŸŸ¡         ðŸŸ¡        ðŸŸ¢
attention â”‚ ðŸŸ¡      âšª         ðŸ”´         ðŸŸ¡        ðŸŸ¡  
mechanismsâ”‚ ðŸŸ¡      ðŸŸ          âšª         ðŸŸ         ðŸŸ¡
capture â”‚  ðŸŸ¢      ðŸŸ¡         ðŸŸ¡         âšª        ðŸŸ 
relationshipsâ”‚ðŸŸ¢      ðŸŸ¡         ðŸŸ¡         ðŸŸ¡        âšª
```

STEP 5: GRAPH NODE COLORING
===========================

NODES colored by MAXIMUM ATTENTION RECEIVED:
```
Graph: max(0.52, 0.19, 0.16, 0.12, 0.09) = 0.52 â†’ ðŸ”´ RED
attention: max(0.52, 0.58, 0.34, 0.21, 0.15) = 0.58 â†’ ðŸ”´ RED  
mechanisms: max(0.18, 0.58, 0.32, 0.28, 0.18) = 0.58 â†’ ðŸ”´ RED
capture: max(0.15, 0.24, 0.32, 0.41, 0.26) = 0.41 â†’ ðŸŸ  ORANGE
relationships: max(0.08, 0.17, 0.22, 0.41, 0.05) = 0.41 â†’ ðŸŸ  ORANGE
```

FINAL COLORED GRAPH VISUALIZATION:
==================================
```
        ðŸ”´ Graph â”€â”€â”€â”€0.52â”€â”€â”€â–º ðŸ”´ attention â”€â”€â”€â”€0.58â”€â”€â”€â–º ðŸ”´ mechanisms
           â†‘                     â†‘                         â†‘
           â”‚0.19                  â”‚0.34                     â”‚0.32
           â”‚                     â”‚                         â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
                                                           â”‚
                                   ðŸŸ  capture â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â†‘     â”‚0.28
                                      â”‚0.41 â”‚
                                      â”‚     â†“
                                   ðŸŸ  relationships
```

ATTENTION FLOW INTERPRETATION:
=============================
1. ðŸ”´ "attention" receives HIGHEST attention (0.58) from "mechanisms" 
2. ðŸ”´ "Graph" strongly attends to "attention" (0.52)
3. ðŸ”´ "mechanisms" gets strong attention from "attention" (0.58)
4. ðŸŸ  "capture" and "relationships" form medium-strength connection (0.41)
5. Strong sequential flow: Graph â†’ attention â†’ mechanisms â†’ capture â†’ relationships

KEY INSIGHTS:
============
â€¢ Core concept words ("Graph", "attention", "mechanisms") form tight cluster
â€¢ Action words ("capture", "relationships") have moderate connections  
â€¢ Attention weights reflect semantic relationships, not just adjacency
â€¢ Color intensity shows information flow and importance in the sentence

INTEGRATION STEPS FOR YOUR VISUALIZATION:
========================================
1. Extract target sentence from paragraph context
2. Compute attention weights using GAT forward pass
3. Apply color mapping to both adjacency matrix and graph nodes
4. Render colored graph with attention-weighted connections
5. Display colored adjacency matrix alongside graph
6. Add interactive hover to show attention values