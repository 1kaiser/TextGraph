<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Graph Attention Networks Explorer</title>
    <link rel="stylesheet" href="gat-explorer.css">
    
    <!-- TensorFlow.js for neural network computations -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0/dist/tf.min.js"></script>
    
    <!-- D3.js for visualizations -->
    <script src="https://d3js.org/d3.v5.min.js"></script>
</head>
<body>
    <div class="main-container">
        <!-- Top Input Section -->
        <div class="input-section">
            <h1>ğŸ§  Graph Attention Networks (GAT) Explorer</h1>
            <div class="paragraph-input">
                <label for="paragraph-input">Enter Paragraph for GAT Processing:</label>
                <textarea id="paragraph-input" placeholder="Enter multiple sentences here for complete GAT analysis..." rows="3">Neural networks learn patterns efficiently. Graph attention mechanisms capture relationships. These models transform natural language processing.</textarea>
                <div class="controls">
                    <button id="process-gat" onclick="processWithGAT()">ğŸš€ Process with GAT</button>
                    <button id="step-through" onclick="stepThroughProcess()">ğŸ“ Step-by-Step</button>
                    <select id="stage-selector">
                        <option value="tokenization">1. Tokenization</option>
                        <option value="embedding">2. Embeddings</option>
                        <option value="attention">3. Attention Computation</option>
                        <option value="aggregation">4. Message Aggregation</option>
                        <option value="final">5. Final Graph</option>
                    </select>
                </div>
            </div>
        </div>

        <!-- Main Content Area -->
        <div class="content-container">
            <!-- Left Panel: ASCII Explanations -->
            <div class="explanation-panel">
                <h2>ğŸ“š Step-by-Step Process</h2>
                
                <div id="step-1" class="explanation-step active">
                    <h3>ğŸ”¤ Step 1: Tokenization</h3>
                    <pre class="ascii-diagram">
INPUT: "Neural networks learn patterns efficiently"
       â†“ (word-level splitting)
TOKENS: ["Neural", "networks", "learn", "patterns", "efficiently"]
        â†“ (index assignment)  
INDICES: [0, 1, 2, 3, 4]

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          TOKEN TO INDEX MAPPING             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Neural     â†’ 0                              â”‚
â”‚ networks   â†’ 1                              â”‚
â”‚ learn      â†’ 2                              â”‚
â”‚ patterns   â†’ 3                              â”‚
â”‚ efficientlyâ†’ 4                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    </pre>
                </div>

                <div id="step-2" class="explanation-step">
                    <h3>ğŸ¯ Step 2: Embedding Lookup</h3>
                    <pre class="ascii-diagram">
TOKEN EMBEDDINGS (256-dimensional vectors):

Neural     â†’ [0.2, -0.1, 0.8, ..., 0.3]
networks   â†’ [0.5, 0.2, -0.3, ..., 0.1] 
learn      â†’ [-0.1, 0.7, 0.4, ..., -0.2]
patterns   â†’ [0.3, -0.5, 0.1, ..., 0.8]
efficientlyâ†’ [0.1, 0.4, -0.6, ..., 0.2]

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           EMBEDDING MATRIX H                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚        dimâ‚€   dimâ‚   dimâ‚‚  ...  dimâ‚‚â‚…â‚…      â”‚
â”‚ tokâ‚€ â”‚  0.2  -0.1   0.8  ...   0.3  â”‚       â”‚
â”‚ tokâ‚ â”‚  0.5   0.2  -0.3  ...   0.1  â”‚       â”‚
â”‚ tokâ‚‚ â”‚ -0.1   0.7   0.4  ...  -0.2  â”‚       â”‚
â”‚ tokâ‚ƒ â”‚  0.3  -0.5   0.1  ...   0.8  â”‚       â”‚
â”‚ tokâ‚„ â”‚  0.1   0.4  -0.6  ...   0.2  â”‚       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    </pre>
                </div>

                <div id="step-3" class="explanation-step">
                    <h3>âš¡ Step 3: Attention Computation</h3>
                    <pre class="ascii-diagram">
ATTENTION MECHANISM:
For each pair (i,j):

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ e_ij = LeakyReLU(a^T [WÂ·h_i || WÂ·h_j])      â”‚
â”‚                    â†‘_____________â†‘          â”‚
â”‚                 transformed   transformed   â”‚
â”‚                 features      features      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ATTENTION SCORES (before normalization):
     0     1     2     3     4
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
0 â”‚ 0.0   2.1   0.8   0.3   0.1 â”‚
1 â”‚ 1.8   0.0   2.5   0.7   0.2 â”‚  
2 â”‚ 0.5   1.9   0.0   2.3   0.6 â”‚
3 â”‚ 0.2   0.8   1.7   0.0   2.0 â”‚
4 â”‚ 0.1   0.3   0.9   1.5   0.0 â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

NORMALIZED ATTENTION (softmax):
     0     1     2     3     4
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
0 â”‚ 0.00  0.65  0.25  0.07  0.03â”‚ â† Row sums to 1.0
1 â”‚ 0.15  0.00  0.70  0.12  0.03â”‚
2 â”‚ 0.08  0.32  0.00  0.55  0.05â”‚
3 â”‚ 0.03  0.12  0.30  0.00  0.55â”‚
4 â”‚ 0.02  0.06  0.22  0.40  0.00â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    </pre>
                </div>

                <div id="step-4" class="explanation-step">
                    <h3>ğŸ”„ Step 4: Message Aggregation</h3>
                    <pre class="ascii-diagram">
MESSAGE PASSING:
h'_i = Ïƒ(Î£â±¼ Î±_ij Â· W Â· hâ±¼)

For token "learn" (index 2):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ h'â‚‚ = Ïƒ(Î±â‚‚â‚€Â·WÂ·hâ‚€ + Î±â‚‚â‚Â·WÂ·hâ‚ + Î±â‚‚â‚‚Â·WÂ·hâ‚‚ +    â”‚
â”‚          Î±â‚‚â‚ƒÂ·WÂ·hâ‚ƒ + Î±â‚‚â‚„Â·WÂ·hâ‚„)               â”‚
â”‚                                             â”‚
â”‚     = Ïƒ(0.08Â·WÂ·hâ‚€ + 0.32Â·WÂ·hâ‚ + 0.00Â·WÂ·hâ‚‚ + â”‚
â”‚         0.55Â·WÂ·hâ‚ƒ + 0.05Â·WÂ·hâ‚„)              â”‚
â”‚                                             â”‚
â”‚ "learn" pays most attention to "patterns"   â”‚
â”‚ (weight 0.55) and "networks" (weight 0.32)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

AGGREGATED FEATURES:
Neural     â†’ h'â‚€ = [0.35, 0.12, -0.1, ..., 0.8]
networks   â†’ h'â‚ = [0.28, -0.05, 0.6, ..., 0.2]
learn      â†’ h'â‚‚ = [0.15, 0.45, 0.3, ..., -0.1]
patterns   â†’ h'â‚ƒ = [0.42, -0.2, 0.1, ..., 0.7]
efficientlyâ†’ h'â‚„ = [0.18, 0.3, -0.4, ..., 0.1]
                    </pre>
                </div>

                <div id="step-5" class="explanation-step">
                    <h3>ğŸ¯ Step 5: Final Graph Representation</h3>
                    <pre class="ascii-diagram">
FINAL ATTENTION GRAPH:
         â•­â”€0.25â”€â•®     â•­â”€0.30â”€â•®
      â•­â”€â”€â”€â”€â”€â•®   â”‚  â•­â”€â”€â”€â”€â”€â•®   â”‚
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Neural  â”‚â”€â”€â”€â”¼â”€â”€â”¼â†’â”‚networks â”‚â”€â”€â”€â”¼â”€â”€â”¼â†’â”‚  learn  â”‚
  â”‚   (0)   â”‚   â”‚  â”‚ â”‚   (1)   â”‚   â”‚  â”‚ â”‚   (2)   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†‘         â”‚  â”‚     â†‘         â”‚  â”‚     â†‘
      â•°â”€0.15â”€â”€â”€â”€â•¯  â”‚     â•°â”€0.32â”€â”€â”€â”€â•¯  â”‚     â•°â”€0.55â”€â”€â•®
                   â•°â”€0.65â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯              â”‚
                                                     â†“
                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                              â”‚patterns â”‚
                                              â”‚   (3)   â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

DENSE ADJACENCY MATRIX:
All connections preserved with learned weights
Used for downstream tasks (classification, etc.)
                    </pre>
                </div>
            </div>

            <!-- Right Panel: Live Visualizations -->
            <div class="visualization-panel">
                <h2>ğŸ¨ Live Visualizations</h2>
                
                <div id="stage-visualization">
                    <!-- Current Stage Display -->
                    <div class="stage-header">
                        <h3 id="current-stage">Stage 1: Tokenization</h3>
                        <div class="stage-progress">
                            <div class="progress-bar">
                                <div id="progress-fill" style="width: 20%"></div>
                            </div>
                            <span id="progress-text">1/5 Steps</span>
                        </div>
                    </div>

                    <!-- Tokenization Visualization -->
                    <div id="tokenization-viz" class="stage-viz active">
                        <div class="tokens-display">
                            <div class="original-text">
                                <span class="label">Original Text:</span>
                                <div id="original-text-display"></div>
                            </div>
                            <div class="arrow-down">â†“</div>
                            <div class="tokens-list">
                                <span class="label">Tokens:</span>
                                <div id="tokens-display"></div>
                            </div>
                        </div>
                    </div>

                    <!-- Embedding Visualization -->
                    <div id="embedding-viz" class="stage-viz">
                        <div class="embeddings-display">
                            <canvas id="embedding-canvas" width="400" height="300"></canvas>
                            <div class="embedding-info">
                                <span class="label">Embedding Dimensions: 256</span>
                                <div id="embedding-stats"></div>
                            </div>
                        </div>
                    </div>

                    <!-- Attention Visualization -->
                    <div id="attention-viz" class="stage-viz">
                        <div class="attention-display">
                            <div class="attention-matrix">
                                <canvas id="attention-canvas" width="400" height="400"></canvas>
                            </div>
                            <div class="attention-info">
                                <span class="label">Attention Weights</span>
                                <div id="attention-stats"></div>
                            </div>
                        </div>
                    </div>

                    <!-- Aggregation Visualization -->
                    <div id="aggregation-viz" class="stage-viz">
                        <div class="message-passing">
                            <canvas id="aggregation-canvas" width="400" height="300"></canvas>
                            <div class="aggregation-info">
                                <span class="label">Message Aggregation</span>
                                <div id="aggregation-stats"></div>
                            </div>
                        </div>
                    </div>

                    <!-- Final Graph Visualization -->
                    <div id="final-viz" class="stage-viz">
                        <div id="final-graph-container">
                            <!-- Our existing text-as-graph visualization will go here -->
                            <div id='text-as-graph-final'></div>
                        </div>
                        <div class="comparison-view">
                            <div class="sequential-graph">
                                <h4>Sequential Graph (Current)</h4>
                                <div id="sequential-visualization"></div>
                            </div>
                            <div class="attention-graph">
                                <h4>GAT Graph (With Attention)</h4>
                                <div id="attention-graph-visualization"></div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Controls -->
                <div class="visualization-controls">
                    <button id="prev-step" onclick="previousStep()">â† Previous</button>
                    <button id="next-step" onclick="nextStep()">Next â†’</button>
                    <button id="auto-play" onclick="autoPlay()">ğŸ¬ Auto Play</button>
                    <div class="speed-control">
                        <label>Speed:</label>
                        <input type="range" id="speed-slider" min="500" max="3000" value="1500">
                        <span id="speed-display">1.5s</span>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script src="gat-explorer.js"></script>
</body>
</html>